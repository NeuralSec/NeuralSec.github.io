---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I received my Bachelor's degree in Optoelectronics Informatics from Huazhong University of Science and Technology (HUST), China, before transitioning to computer science and information security for my doctoral studies in Australia, conducted jointly with CSIRO's Data61. Since 2020, 
I have continued my research career at Data61, first as a CERC Postdoctoral Fellow and now as a Research Scientist, focusing on machine learning security and privacy.

My research interests lie at the intersection of adversarial robustness, neural backdoors, robustness/privacy certification, and the real-world security and privacy of machine learning systems. 
I focus particularly on certified robustness, certified data learnability at scale, data privacy and learnability control, as well as red-teaming and defensive strategies for ML systems.
I publish regularly in leading venues such as IEEE S&P, NDSS, USENIX Security, NeurIPS, ICML, AAAI, WWW, IEEE TDSC, and IEEE TIFS, and I serve on the program committees and review boards of major international conferences and journals including NDSS, IEEE S&P, USENIX Security, WWW, AAAI, NeurIPS, IEEE TDSC, IEEE TIFS, IEEE TNNLS, and IEEE TIP. 
My work has been recognized with awards such as the NDSS Distinguished Paper Award, and has been featured in major national media outlets including ABC News, 7 News, The Age, and The Sydney Morning Herald.
Outside of research, I have been playing drums since 2013 and enjoy table tennis as my favorite weekly sport.

---

# **News**
<div style="overflow-y: scroll; height:200px; font-size: 16px" markdown=1>

**[Jun. 2025]** We are excited to host the [LAMPS](https://lamps-ccs.github.io/home/) workshop, colocated with ACM CCS 2025. We invite you to submit your high-quality research!<br>
**[Feb. 2025]** Our paper "Provably Unlearnable Data Examples" got the Distinguished Paper Award at NDSS 2025!<br>
**[Jan. 2025]** One paper on certified robustness of deep reinforcement learning and two papers on perturbative protections for audio data have been accepted to USENIX Security'25 Cycle 1.<br>
**[Jan. 2025]** One paper on AI model availability control via modulation has been accepted to WWW'25.<br>
**[Nov. 2024]** Our paper on certified learnability and another on reinforcement unlearning have been accepted to NDSS'25.<br>
**[Jul. 2024]** I am invited to serve as a PC member for [IEEE SaTML'25](https://satml.org/).<br>
**[Jun. 2024]** I am invited to serve as a PC member for [CCS'24-LAMPS](https://lamps-ccs.com) and the proceedings chair for [AJCAI'24](https://ajcai2024.org/).<br>
**[May. 2024]** Our paper improving double sampling smoothing for addressing curse of dimensionality in randomized smoothing is accepted to ICML'24.<br>
**[Apr. 2024]** I am invited to serve as a TPC member for [NDSS'25](https://www.ndss-symposium.org/ndss2025/).<br>
**[Mar. 2024]** Two papers are accepted to IEEE SP'24 workshop and TDSC, respectively.<br>
**[Dec. 2023]** Our paper in reinforcement adversarial attack against video recognition is accepted to AAAI'24.<br>
**[Oct. 2023]** One paper in face recognition anti-spoofing is accepted to NeurIPS'23.<br>
**[Sep. 2023]** I will serve as a reviewer for TheWebConf'24.<br>
**[Jun. 2023]** I am invited to serve as a PC member for ACISP'24.<br>
**[Nov. 2022]** One paper in style-transfer-based adversarial attack against video classification sytems is accepted to IEEE SP'23.<br>
**[Oct. 2022]** Our paper in neural backdoor detection is accepted to NDSS'23.

</div>

---

# **My Research Focuses**
Certified robustness/data learnability at scale:
- Certified learnability for data learnability control (*NDSS’25*)
- Certified robustness of DRL agents (*USENIX Sec’25*)
- Curse of dimensionality in certified robustness (*ICML’24*)

Data privacy and learnability control:
- Perturbative availability poisons (*NDSS’25, USENIX Sec’25*)
- Other perturbative protections and unlearning (*NDSS’25, USENIX Sec’25, ...*)

Red teaming and defensive solutions for ML systems:
- Red teaming and robustness evaluation (*SP’23, AAAI’24, ...*)
- Defenses against backdoors and adversarial attacks (*NDSS’23, NeurIPS’23, ACSAC’19, ...*)

My ultimate goal is to make AI truly trustworthy through *provable guarantees*, *causality*, and *human alignment*.
For prospective students and researchers interested in collaboration: Please feel free to shoot me an email if these align with your research interests.

---

# **Supervision and Mentorship**
I have been fortunate to supervise/mentor and work with the following talented students (listed in alphabetical order by last name):
- [Yuxin Cao](https://yuxincao22.github.io) (Tsinghua University --> NUS)
- Siji Chen (Tsinghua University)
- Brayden Killeen (RMIT)
- [Chaoran Li](https://scholar.google.com/citations?user=K4ZJJtkAAAAJ&hl=en) (Swinburne University of Technology --> Li Auto)
- [Wanlun Ma](https://scholar.google.com/citations?user=W5z9XB8AAAAJ&hl=en) (Swinburne University of Technology)
- Youwei Shu (Tsinghua University --> NUS)
- [Zihan Wang](https://www.zihan.com.au) (University of Queensland)
- [Kai Ye](https://scholar.google.com.au/citations?hl=en&user=dWvWMv8AAAAJ) (Tsinghua University --> HKU)

---

# **Media Coverage**
- [CSIRO](https://www.csiro.au/en/news/All/News/2025/August/New-research-could-block-AI-learning-from-your-online-content?utm_source=D61SM25&utm_medium=D61SM25&utm_campaign=AICP25)
- [ABC News](https://www.abc.net.au/news/2025-08-12/csiro-develops-algorithm-to-prevent-deepfakes/105641122)
- [7 National News](https://www.youtube.com/watch?v=n1U6yBOc2QM)
- [The Age](https://www.theage.com.au/technology/csiro-breakthrough-shields-against-sexualised-ai-deepfakes-20250808-p5mlfm.html)
- [The Sydney Morning Herald](https://www.smh.com.au/technology/csiro-breakthrough-shields-against-sexualised-ai-deepfakes-20250808-p5mlfm.html)
